{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_miller import split_classes, continues_classes, continues_classes_idle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fname = 'motor_imagery.npz'\n",
    "data = np.load(fname, allow_pickle=True)['dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['t_off', 'stim_id', 't_on', 'srate', 'V', 'scale_uv', 'locs', 'hemisphere', 'lobe', 'gyrus', 'Brodmann_Area'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.zeros((10,10))\n",
    "len(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17160, 1, 20, 3])\n",
      "(10, 11, 12, 13, 3, 20)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class AdjustableMeanPooling(nn.Module):\n",
    "    def __init__(self, kernel_size=(1, 10)):\n",
    "        super(AdjustableMeanPooling, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool = nn.AvgPool2d(kernel_size=kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "        original_shape = x.shape\n",
    "        \n",
    "        *batch_dims, D, C = original_shape\n",
    "        \n",
    "        B = np.prod(batch_dims)\n",
    "        x = x.view(B, 1, C, D)\n",
    "        \n",
    "        x = self.pool(x)        \n",
    "        x = x.view(*batch_dims, x.shape[-1], x.shape[-2])  \n",
    "        \n",
    "        return x.numpy()\n",
    "\n",
    "kernel_size = (1, 5) \n",
    "input_tensor = np.random.randn(10,11,12, 13, 16, 20)  \n",
    "\n",
    "pooling_layer = AdjustableMeanPooling(kernel_size=kernel_size)\n",
    "output_tensor = pooling_layer(input_tensor)\n",
    "print(output_tensor.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 5, 13, 46, 3000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def threshold_eeg_data(ecog_data, threshold):\n",
    "    '''\n",
    "    Converts ECoG data into a neural-like binary format with a given threshold.\n",
    "    \n",
    "    Args:\n",
    "    - ecog_data (numpy.ndarray): Input ECoG data with shape (..., D, C),\n",
    "                                  where D is timepoints and C is channels.\n",
    "    - threshold (float): The threshold value. Values above this threshold are set to 1, otherwise to 0.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: ECoG data in a binary format, same shape as input.\n",
    "    '''\n",
    "    # Apply threshold to the data\n",
    "    binary_data = np.where(ecog_data > threshold, 1, 0)\n",
    "    \n",
    "    return binary_data\n",
    "\n",
    "# Example usage:\n",
    "# Suppose your ECoG data has shape (840, 46, 3000)\n",
    "ecog_data = np.random.rand(5,5,5,13, 46, 3000)  # Simulating ECoG data\n",
    "threshold = 0.5  # Example threshold\n",
    "\n",
    "binary_ecog_data = threshold_eeg_data(ecog_data, threshold)\n",
    "print(binary_ecog_data.shape)  # Should be (840, 46, 3000), with b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 3, 17160])\n",
      "(10, 11, 12, 13, 3, 20)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class AdjustableModePooling(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super(AdjustableModePooling, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "        original_shape = x.shape\n",
    "        *batch_dims, D, C = original_shape\n",
    "        \n",
    "        B = np.prod(batch_dims)\n",
    "        x = x.view(B, 1, C, D)\n",
    "        \n",
    "        pooled_results = []\n",
    "        \n",
    "        for i in range(0, C - self.kernel_size[0] + 1, self.kernel_size[0]):  \n",
    "            pool = []\n",
    "            for j in range(0, D - self.kernel_size[1] + 1, self.kernel_size[1]):  \n",
    "                window = x[:, :, i:i+self.kernel_size[0], j:j+self.kernel_size[1]]\n",
    "                \n",
    "                mode_values, _ = torch.mode(window.view(-1, window.shape[-1]), dim=1)\n",
    "                pool.append(mode_values)\n",
    "            pooled_results.append(torch.stack(pool, dim=0))\n",
    "\n",
    "        pooled_results = torch.stack(pooled_results, dim=0)\n",
    "        pooled_results = pooled_results.view(*batch_dims, pooled_results.shape[1], pooled_results.shape[0])\n",
    "        \n",
    "        return pooled_results.numpy()\n",
    "\n",
    "kernel_size = (1, 5) \n",
    "input_tensor = np.random.randn(10,11,12, 13, 16, 20)  \n",
    "\n",
    "pooling_layer = AdjustableModePooling(kernel_size=kernel_size)\n",
    "output_tensor = pooling_layer(input_tensor)\n",
    "print(output_tensor.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import welch\n",
    "import numpy as np\n",
    "\n",
    "def compute_psd(data, fs, log_scale=True):\n",
    "    \"\"\"\n",
    "    Computes the Power Spectral Density (PSD) of the input data.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): Input data, typically shape (..., D, C).\n",
    "        fs (float): Sampling frequency.\n",
    "        log_scale (bool): If True, returns PSD in decibels (log scale).\n",
    "\n",
    "    Returns:\n",
    "        tuple: Frequencies and PSD values.\n",
    "    \"\"\"\n",
    "    f, Pxx = welch(data, fs, nperseg=256, axis=-2)\n",
    "    return f, 10 * np.log10(Pxx) if log_scale else Pxx\n",
    "\n",
    "def filter_psd(frequencies, psd_values, bands):\n",
    "    \"\"\"\n",
    "    Filters PSD values based on a list of frequency bands.\n",
    "\n",
    "    Parameters:\n",
    "        frequencies (np.ndarray): Array of frequency bins.\n",
    "        psd_values (np.ndarray): PSD values corresponding to the frequency bins.\n",
    "        bands (list of tuples): List of frequency bands as (low, high).\n",
    "\n",
    "    Returns:\n",
    "        list: A list where each item is the PSD values filtered by a specific band.\n",
    "    \"\"\"\n",
    "    filtered_psd_list = []\n",
    "    for low_cut, high_cut in bands:\n",
    "        mask = (frequencies >= low_cut) & (frequencies <= high_cut)\n",
    "        filtered_psd = psd_values[..., mask, :]\n",
    "        filtered_psd_list.append(filtered_psd)\n",
    "    return filtered_psd_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 3000, 46)\n",
      "(10, 129, 46)\n",
      "Number of bands: 5\n",
      "Band (0.5, 4) - PSD shape: (10, 1, 46)\n",
      "Band (4, 8) - PSD shape: (10, 1, 46)\n",
      "Band (8, 13) - PSD shape: (10, 1, 46)\n",
      "Band (13, 30) - PSD shape: (10, 4, 46)\n",
      "Band (30, 50) - PSD shape: (10, 5, 46)\n"
     ]
    }
   ],
   "source": [
    "# Example signal\n",
    "fs = 1000  # Sampling frequency\n",
    "D = 3000  # Time points\n",
    "C = 46  # Channels\n",
    "N = 10  # Number of samples\n",
    "\n",
    "np.random.seed(42)\n",
    "signal = np.random.randn(N, D, C)\n",
    "\n",
    "# Compute PSD\n",
    "freqs, psd = compute_psd(signal, fs)\n",
    "print(signal.shape)\n",
    "print(psd.shape)\n",
    "\n",
    "# Define frequency bands\n",
    "bands = [(0.5, 4), (4, 8), (8, 13), (13, 30), (30, 50)]\n",
    "\n",
    "# Filter PSD based on bands\n",
    "filtered_psd_list = filter_psd(freqs, psd, bands)\n",
    "\n",
    "# Output shapes and example content\n",
    "print(\"Number of bands:\", len(filtered_psd_list))\n",
    "for i, band_psd in enumerate(filtered_psd_list):\n",
    "    print(f\"Band {bands[i]} - PSD shape: {band_psd.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376400 369440 10160 359281\n",
      "376600 369640 10160 359481\n",
      "390680 383720 10120 373601\n",
      "390320 383360 10160 373201\n",
      "376240 369280 10120 359161\n",
      "376840 369880 10160 359721\n",
      "390720 383760 10120 373641\n",
      "390200 383240 10120 373121\n",
      "390640 383680 10200 373481\n",
      "390160 383200 10200 373001\n",
      "390720 383760 10120 373641\n",
      "390200 383240 10120 373121\n",
      "390240 383280 10120 373161\n",
      "390920 383960 10120 373841\n"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    for j in range(2):\n",
    "        print(data[i][j]['V'].shape[0], data[i][j]['t_off'][-1], data[i][j]['t_on'][0], data[i][j]['t_off'][-1] - data[i][j]['t_on'][0] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14680"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "390920  - 376240"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7340"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(390920  - 376240) // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]['stim_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]['V'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros(data[0][0]['V'][:,:46].shape).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]['t_on'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat1 = data[1][0] \n",
    "\n",
    "discrete_data, extra_info_dat1 = split_classes(data=dat1)\n",
    "\n",
    "continues_data_1_dat1, extra_info_1_dat1 = continues_classes(data=dat1)\n",
    "\n",
    "continues_data_2_dat1, extra_info_2_dat1 = continues_classes_idle(data=dat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 3000, 46)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continues_data_1_dat1['stim_id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13, 13, 14, 13, 13, 14, 14, 14, 13],\n",
       "       [ 1,  1,  4,  1,  1,  4, 13,  4, 15]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[11,11,12,11,11,12,12,12,11] , [1,1,2,1,1,2,11,2,13]]\n",
    "a = np.array(a)\n",
    "\n",
    "# (a == 12).astype(int)\n",
    "a = a+2\n",
    "a[a == 3] = 1\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat2 = data[2][0] \n",
    "\n",
    "tongue_data_dat2, hand_data_dat2, extra_info_dat2 = split_classes(data=dat2)\n",
    "\n",
    "continues_data_1_dat2, extra_info_1_dat2 = continues_classes(data=dat2)\n",
    "\n",
    "continues_data_2_dat2, extra_info_2_dat2 = continues_classes_idle(data=dat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 10000\n",
    "output_dimension = 3\n",
    "\n",
    "from cebra import CEBRA\n",
    "\n",
    "cebra_posdir3_model = CEBRA(model_architecture='offset10-model',\n",
    "                        batch_size=64,\n",
    "                        learning_rate=3e-4,\n",
    "                        temperature=1,\n",
    "                        output_dimension=output_dimension,\n",
    "                        max_iterations=max_iterations,\n",
    "                        distance='cosine',\n",
    "                        conditional='time_delta',\n",
    "                        device='cuda_if_available',\n",
    "                        verbose=True,\n",
    "                        time_offsets=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_posdir3_model.fit(continues_data_2_dat1['V'], continues_data_2_dat1['stim_id'])\n",
    "cebra_posdir3 = cebra_posdir3_model.transform(continues_data_2_dat1['V'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_posdir3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continues_data_2_dat1['stim_id'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cebra_posdir3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import plotly.express as px\n",
    "\n",
    "# # Example data\n",
    "# # Replace these with your actual data\n",
    "# points = cebra_posdir3  # Shape: (390680, 3)\n",
    "# labels = continues_data_2_dat1['stim_id'][:,0]  # Shape: (390680,)\n",
    "\n",
    "# # Create a DataFrame for easier handling (optional)\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(points, columns=[\"X\", \"Y\", \"Z\"])\n",
    "# df[\"Label\"] = labels\n",
    "\n",
    "# # Create a dynamic 3D scatter plot\n",
    "# fig = px.scatter_3d(\n",
    "#     df,\n",
    "#     x=\"X\", \n",
    "#     y=\"Y\", \n",
    "#     z=\"Z\", \n",
    "#     color=\"Label\",  # Color by labels\n",
    "#     color_continuous_scale=\"rainbow\",\n",
    "#     title=\"Dynamic 3D Scatter Plot\",\n",
    "#     labels={\"Label\": \"Classes\"},\n",
    "#     opacity=0.8\n",
    "# )\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import plotly.express as px\n",
    "\n",
    "# # Example data\n",
    "# # Replace these with your actual data\n",
    "# points = cebra_posdir3  # Shape: (390680, 3)\n",
    "# labels = continues_data_2_dat1['stim_id'][:,0]  # Shape: (390680,)\n",
    "\n",
    "# # Create a DataFrame for easier handling (optional)\n",
    "# import pandas as pd\n",
    "# df = pd.DataFrame(points, columns=[\"X\", \"Y\", \"Z\"])\n",
    "# df[\"Label\"] = labels\n",
    "\n",
    "# # Create a dynamic 3D scatter plot\n",
    "# fig = px.scatter_3d(\n",
    "#     df,\n",
    "#     x=\"X\", \n",
    "#     y=\"Y\", \n",
    "#     z=\"Z\", \n",
    "#     color=\"Label\",  # Color by labels\n",
    "#     color_continuous_scale=\"rainbow\",\n",
    "#     title=\"Dynamic 3D Scatter Plot\",\n",
    "#     labels={\"Label\": \"Classes\"},\n",
    "#     opacity=0.8\n",
    "# )\n",
    "\n",
    "# fig.update_traces(marker=dict(size=2))\n",
    "\n",
    "# # Show the plot\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
